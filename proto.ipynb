{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/colin/git/decp-airflow\n"
     ]
    }
   ],
   "source": [
    "# *** INITIALISATION ***#\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "import datetime\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Timestamp\n",
    "date_now = datetime.date.today().isoformat()\n",
    "datetime_now = datetime.datetime.now().isoformat()\n",
    "\n",
    "root_dir = os.path.abspath(os.curdir)\n",
    "print(root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DECP d'aujourd'hui déjà téléchargées\n"
     ]
    }
   ],
   "source": [
    "# *** TÉLÉCHARGEMENT ***#\n",
    "\n",
    "import pandas as pd\n",
    "from requests import get\n",
    "\n",
    "# decp_augmente_valides_file: Path = Path(f'data/decp_augmente_valides_{date_now}.csv')\n",
    "decp_augmente_valides_file: Path = Path(f\"data/decp_augmente_valides_2024-04-12.csv\")\n",
    "\n",
    "\n",
    "if not (os.path.exists(decp_augmente_valides_file)):\n",
    "    request = get(os.getenv(\"DECP_ENRICHIES_VALIDES_URL\"))\n",
    "    with open(decp_augmente_valides_file, \"wb\") as file:\n",
    "        file.write(request.content)\n",
    "else:\n",
    "    print(\"DECP d'aujourd'hui déjà téléchargées\")\n",
    "\n",
    "df: pd.DataFrame = pd.read_csv(\n",
    "    decp_augmente_valides_file, sep=\";\", dtype=\"object\", index_col=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *** ANALYSE DE BASE ***#\n",
    "\n",
    "# df.info(verbose=True)\n",
    "# obsolete number of rows 994123\n",
    "# valid number of rows 837115"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import NaN\n",
    "\n",
    "df.replace([NaN, None], \"\", inplace=True, regex=False)\n",
    "# df[['id', 'datePublicationDonnees']].loc[df['datePublicationDonnees'].str.contains(\"September\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *** REDRESSEMENT ***#\n",
    "\n",
    "# Dates\n",
    "\n",
    "columns_date = [\"datePublicationDonnees\", \"dateNotification\"]\n",
    "\n",
    "date_replacements = {\n",
    "    # ID marché invalide et SIRET de l'acheteur\n",
    "    \"0002-11-30\": \"\",\n",
    "    \"September, 16 2021 00:00:00\": \"2021-09-16\",  # 20007695800012 19830766200017 (plein !)\n",
    "    \"16 2021 00:00:00\": \"\",\n",
    "    \"0222-04-29\": \"2022-04-29\",  # 202201L0100\n",
    "    \"0021-12-05\": \"2022-12-05\",  # 20222022/1400\n",
    "    \"0001-06-21\": \"\",  # 0000000000000000 21850109600018\n",
    "    \"0019-10-18\": \"\",  # 0000000000000000 34857909500012\n",
    "    \"5021-02-18\": \"2021-02-18\",  # 20213051200 21590015000016\n",
    "    \"2921-11-19\": \"\",  # 20220057201 20005226400013\n",
    "    \"0022-04-29\": \"2022-04-29\",  # 2022AOO-GASL0100 25640454200035\n",
    "}\n",
    "\n",
    "for col in columns_date:\n",
    "    df[col] = df[col].replace(date_replacements, regex=False)\n",
    "\n",
    "\n",
    "# Nombres\n",
    "\n",
    "df[\"dureeMois\"] = df[\"dureeMois\"].replace(\"\", NaN)\n",
    "df[\"montant\"] = df[\"montant\"].replace(\"\", NaN)\n",
    "\n",
    "# Identifiants de marchés\n",
    "\n",
    "id_replacements = {\"[,\\./]\": \"_\"}\n",
    "\n",
    "df[\"id\"] = df[\"id\"].replace(id_replacements, regex=True)\n",
    "\n",
    "# Nature\n",
    "\n",
    "nature_replacements = {\"Marche\": \"Marché\", \"subsequent\": \"subséquent\"}\n",
    "\n",
    "df[\"nature\"] = df[\"nature\"].str.capitalize()\n",
    "df[\"nature\"] = df[\"nature\"].replace(nature_replacements, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 837135 entries, 0 to 837134\n",
      "Data columns (total 54 columns):\n",
      " #   Column                              Non-Null Count   Dtype         \n",
      "---  ------                              --------------   -----         \n",
      " 0   titulaire_denominationSociale_1     837135 non-null  object        \n",
      " 1   titulaire_id_1                      837135 non-null  object        \n",
      " 2   titulaire_typeIdentifiant_1         837135 non-null  object        \n",
      " 3   titulaire_denominationSociale_2     837135 non-null  object        \n",
      " 4   titulaire_id_2                      837135 non-null  object        \n",
      " 5   titulaire_typeIdentifiant_2         837135 non-null  object        \n",
      " 6   titulaire_denominationSociale_3     837135 non-null  object        \n",
      " 7   titulaire_id_3                      837135 non-null  object        \n",
      " 8   titulaire_typeIdentifiant_3         837135 non-null  object        \n",
      " 9   procedure                           837135 non-null  object        \n",
      " 10  nature                              837135 non-null  object        \n",
      " 11  codeCPV                             837135 non-null  object        \n",
      " 12  dureeMois                           837115 non-null  Int64         \n",
      " 13  datePublicationDonnees              834279 non-null  datetime64[ns]\n",
      " 14  id                                  837135 non-null  object        \n",
      " 15  formePrix                           837135 non-null  object        \n",
      " 16  dateNotification                    837115 non-null  datetime64[ns]\n",
      " 17  objet                               837135 non-null  object        \n",
      " 18  montant                             837095 non-null  float64       \n",
      " 19  acheteur.id                         837135 non-null  object        \n",
      " 20  source                              837135 non-null  object        \n",
      " 21  lieuExecution.code                  837135 non-null  object        \n",
      " 22  lieuExecution.typeCode              837135 non-null  object        \n",
      " 23  lieuExecution.nom                   837135 non-null  object        \n",
      " 24  acheteur.nom                        837135 non-null  object        \n",
      " 25  considerationsSociales              837135 non-null  object        \n",
      " 26  considerationsEnvironnementales     837135 non-null  object        \n",
      " 27  technique                           837135 non-null  object        \n",
      " 28  modaliteExecution                   837135 non-null  object        \n",
      " 29  marcheInnovant                      837135 non-null  object        \n",
      " 30  attributionAvance                   837135 non-null  object        \n",
      " 31  sousTraitanceDeclaree               837135 non-null  object        \n",
      " 32  idAccordCadre                       837135 non-null  object        \n",
      " 33  ccag                                837135 non-null  object        \n",
      " 34  offresRecues                        837135 non-null  object        \n",
      " 35  typeGroupementOperateurs            837135 non-null  object        \n",
      " 36  actesSousTraitance                  837135 non-null  object        \n",
      " 37  modificationsActesSousTraitance     837135 non-null  object        \n",
      " 38  TypePrix                            837135 non-null  object        \n",
      " 39  tauxAvance                          837135 non-null  object        \n",
      " 40  origineUE                           837135 non-null  object        \n",
      " 41  origineFrance                       837135 non-null  object        \n",
      " 42  created_at                          837135 non-null  object        \n",
      " 43  typesPrix                           837135 non-null  object        \n",
      " 44  typePrix                            837135 non-null  object        \n",
      " 45  updated_at                          837135 non-null  object        \n",
      " 46  booleanModification                 837135 non-null  object        \n",
      " 47  objetModification                   837135 non-null  object        \n",
      " 48  dureeMoisModification               837135 non-null  object        \n",
      " 49  titulairesModification              837135 non-null  object        \n",
      " 50  datePublicationDonneesModification  837135 non-null  object        \n",
      " 51  montantModification                 837135 non-null  object        \n",
      " 52  dateNotificationModification        837135 non-null  object        \n",
      " 53  idModification                      837135 non-null  object        \n",
      "dtypes: Int64(1), datetime64[ns](2), float64(1), object(50)\n",
      "memory usage: 345.7+ MB\n"
     ]
    }
   ],
   "source": [
    "# ***  TYPES DE DONNÉES ***#\n",
    "\n",
    "numeric_dtypes = {\n",
    "    \"dureeMois\": \"Int64\",  # contrairement à int64, Int64 autorise les valeurs nulles https://pandas.pydata.org/docs/user_guide/integer_na.html\n",
    "    \"montant\": \"float64\",\n",
    "}\n",
    "\n",
    "for column in numeric_dtypes:\n",
    "    df[column] = df[column].astype(numeric_dtypes[column])\n",
    "\n",
    "\n",
    "date_dtypes = [\"datePublicationDonnees\", \"dateNotification\"]\n",
    "\n",
    "for column in date_dtypes:\n",
    "    df[column] = pd.to_datetime(df[column], format=\"mixed\", dayfirst=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Marché', 'Accord-cadre', 'MARCHE', 'Marché subséquent',\n",
       "       'ACCORD-CADRE', 'MARCHE SUBSEQUENT', '', 'Marché de partenariat',\n",
       "       'MARCHE DE PARTENARIAT'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# megalis-bretagne\n",
      "Nombre de marchés : 21728\n",
      "Nombre d'acheteurs uniques : 707\n",
      "\n",
      "\n",
      "# data.gouv.fr_pes\n",
      "Nombre de marchés : 279345\n",
      "Nombre d'acheteurs uniques : 10298\n",
      "\n",
      "\n",
      "# e-marchespublics\n",
      "Nombre de marchés : 75614\n",
      "Nombre d'acheteurs uniques : 1630\n",
      "\n",
      "\n",
      "# data.gouv.fr_aife\n",
      "Nombre de marchés : 255022\n",
      "Nombre d'acheteurs uniques : 3422\n",
      "\n",
      "\n",
      "# decp_aws\n",
      "Nombre de marchés : 125312\n",
      "Nombre d'acheteurs uniques : 3759\n",
      "\n",
      "\n",
      "# marches-publics.info\n",
      "Nombre de marchés : 71327\n",
      "Nombre d'acheteurs uniques : 4787\n",
      "\n",
      "\n",
      "# ternum-bfc\n",
      "Nombre de marchés : 8747\n",
      "Nombre d'acheteurs uniques : 385\n",
      "\n",
      "\n",
      "# \n",
      "Nombre de marchés : 40\n",
      "Nombre d'acheteurs uniques : 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ***  ANALYSES AVANCÉES ***#\n",
    "\n",
    "# Les sources d'où proviennent les données\n",
    "sources = df[\"source\"].unique()\n",
    "\n",
    "for source in sources:\n",
    "    print(\n",
    "        f\"\"\"\n",
    "# {source}\n",
    "Nombre de marchés : {df[[\"source\"]].loc[df[\"source\"]==source].index.size}\n",
    "Nombre d'acheteurs uniques : {len(df[[\"acheteur.id\", \"source\"]].loc[df[\"source\"]==source]['acheteur.id'].unique())}\n",
    "\"\"\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VERS LE FORMAT DECP-TABLE-SCHEMA #\n",
    "\n",
    "# Explosion des champs titulaires sur plusieurs lignes\n",
    "\n",
    "df[\"titulaire.id\"] = [[] for r in range(len(df))]\n",
    "df[\"titulaire.denominationSociale\"] = [[] for r in range(len(df))]\n",
    "df[\"titulaire.typeIdentifiant\"] = [[] for r in range(len(df))]\n",
    "\n",
    "for num in range(1, 4):\n",
    "    mask = df[f\"titulaire_id_{num}\"] != \"\"\n",
    "    df.loc[mask, \"titulaire.id\"] += df.loc[mask, f\"titulaire_id_{num}\"].apply(\n",
    "        lambda x: [x]\n",
    "    )\n",
    "    df.loc[mask, \"titulaire.denominationSociale\"] += df.loc[\n",
    "        mask, f\"titulaire_denominationSociale_{num}\"\n",
    "    ].apply(lambda x: [x])\n",
    "    df.loc[mask, \"titulaire.typeIdentifiant\"] += df.loc[\n",
    "        mask, f\"titulaire_typeIdentifiant_{num}\"\n",
    "    ].apply(lambda x: [x])\n",
    "\n",
    "df = df.explode(\n",
    "    [\"titulaire.id\", \"titulaire.denominationSociale\", \"titulaire.typeIdentifiant\"],\n",
    "    ignore_index=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 930599 entries, 0 to 930598\n",
      "Data columns (total 60 columns):\n",
      " #   Column                              Non-Null Count   Dtype         \n",
      "---  ------                              --------------   -----         \n",
      " 0   titulaire_denominationSociale_1     930599 non-null  object        \n",
      " 1   titulaire_id_1                      930599 non-null  object        \n",
      " 2   titulaire_typeIdentifiant_1         930599 non-null  object        \n",
      " 3   titulaire_denominationSociale_2     930599 non-null  object        \n",
      " 4   titulaire_id_2                      930599 non-null  object        \n",
      " 5   titulaire_typeIdentifiant_2         930599 non-null  object        \n",
      " 6   titulaire_denominationSociale_3     930599 non-null  object        \n",
      " 7   titulaire_id_3                      930599 non-null  object        \n",
      " 8   titulaire_typeIdentifiant_3         930599 non-null  object        \n",
      " 9   procedure                           930599 non-null  object        \n",
      " 10  nature                              930599 non-null  object        \n",
      " 11  codeCPV                             930599 non-null  object        \n",
      " 12  dureeMois                           930559 non-null  Int64         \n",
      " 13  datePublicationDonnees              927287 non-null  datetime64[ns]\n",
      " 14  id                                  930599 non-null  object        \n",
      " 15  formePrix                           930599 non-null  object        \n",
      " 16  dateNotification                    930559 non-null  datetime64[ns]\n",
      " 17  objet                               930599 non-null  object        \n",
      " 18  montant                             930539 non-null  float64       \n",
      " 19  acheteur.id                         930599 non-null  object        \n",
      " 20  source                              930599 non-null  object        \n",
      " 21  lieuExecution.code                  930599 non-null  object        \n",
      " 22  lieuExecution.typeCode              930599 non-null  object        \n",
      " 23  lieuExecution.nom                   930599 non-null  object        \n",
      " 24  acheteur.nom                        930599 non-null  object        \n",
      " 25  considerationsSociales              930599 non-null  object        \n",
      " 26  considerationsEnvironnementales     930599 non-null  object        \n",
      " 27  technique                           930599 non-null  object        \n",
      " 28  modaliteExecution                   930599 non-null  object        \n",
      " 29  marcheInnovant                      930599 non-null  object        \n",
      " 30  attributionAvance                   930599 non-null  object        \n",
      " 31  sousTraitanceDeclaree               930599 non-null  object        \n",
      " 32  idAccordCadre                       930599 non-null  object        \n",
      " 33  ccag                                930599 non-null  object        \n",
      " 34  offresRecues                        930599 non-null  object        \n",
      " 35  typeGroupementOperateurs            930599 non-null  object        \n",
      " 36  actesSousTraitance                  930599 non-null  object        \n",
      " 37  modificationsActesSousTraitance     930599 non-null  object        \n",
      " 38  TypePrix                            930599 non-null  object        \n",
      " 39  tauxAvance                          930599 non-null  object        \n",
      " 40  origineUE                           930599 non-null  object        \n",
      " 41  origineFrance                       930599 non-null  object        \n",
      " 42  created_at                          930599 non-null  object        \n",
      " 43  typesPrix                           930599 non-null  object        \n",
      " 44  typePrix                            930599 non-null  object        \n",
      " 45  updated_at                          930599 non-null  object        \n",
      " 46  booleanModification                 930599 non-null  object        \n",
      " 47  objetModification                   930599 non-null  object        \n",
      " 48  dureeMoisModification               930599 non-null  object        \n",
      " 49  titulairesModification              930599 non-null  object        \n",
      " 50  datePublicationDonneesModification  930599 non-null  object        \n",
      " 51  montantModification                 930599 non-null  object        \n",
      " 52  dateNotificationModification        930599 non-null  object        \n",
      " 53  idModification                      930599 non-null  object        \n",
      " 54  titulaire.id                        928313 non-null  object        \n",
      " 55  titulaire.denominationSociale       928313 non-null  object        \n",
      " 56  titulaire.typeIdentifiant           928313 non-null  object        \n",
      " 57  uid                                 930599 non-null  object        \n",
      " 58  donneesActuelles                    930599 non-null  object        \n",
      " 59  anomalies                           930599 non-null  object        \n",
      "dtypes: Int64(1), datetime64[ns](2), float64(1), object(56)\n",
      "memory usage: 426.9+ MB\n"
     ]
    }
   ],
   "source": [
    "# Ajout colonnes manquantes\n",
    "\n",
    "df[\"uid\"] = df[\"acheteur.id\"] + df[\"id\"]\n",
    "df[\"donneesActuelles\"] = \"\"  # TODO\n",
    "df[\"anomalies\"] = \"\"  # TODO\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.\nA suitable version of pyarrow or fastparquet is required for parquet support.\nTrying to import the above resulted in these errors:\n - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.\n - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 35\u001b[0m\n\u001b[1;32m     31\u001b[0m df_sans_titulaires \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mdrop_duplicates()\n\u001b[1;32m     32\u001b[0m df_sans_titulaires\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdecp-sans-titulaires.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m---> 35\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdecp.parquet\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/git/decp-airflow/.venv/lib/python3.10/site-packages/pandas/util/_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    329\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    330\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    331\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    332\u001b[0m     )\n\u001b[0;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/git/decp-airflow/.venv/lib/python3.10/site-packages/pandas/core/frame.py:3113\u001b[0m, in \u001b[0;36mDataFrame.to_parquet\u001b[0;34m(self, path, engine, compression, index, partition_cols, storage_options, **kwargs)\u001b[0m\n\u001b[1;32m   3032\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   3033\u001b[0m \u001b[38;5;124;03mWrite a DataFrame to the binary parquet format.\u001b[39;00m\n\u001b[1;32m   3034\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3109\u001b[0m \u001b[38;5;124;03m>>> content = f.read()\u001b[39;00m\n\u001b[1;32m   3110\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   3111\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparquet\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m to_parquet\n\u001b[0;32m-> 3113\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mto_parquet\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3114\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3115\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3116\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3117\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3118\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3119\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpartition_cols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpartition_cols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3120\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3121\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3122\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/git/decp-airflow/.venv/lib/python3.10/site-packages/pandas/io/parquet.py:476\u001b[0m, in \u001b[0;36mto_parquet\u001b[0;34m(df, path, engine, compression, index, storage_options, partition_cols, filesystem, **kwargs)\u001b[0m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(partition_cols, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    475\u001b[0m     partition_cols \u001b[38;5;241m=\u001b[39m [partition_cols]\n\u001b[0;32m--> 476\u001b[0m impl \u001b[38;5;241m=\u001b[39m \u001b[43mget_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    478\u001b[0m path_or_buf: FilePath \u001b[38;5;241m|\u001b[39m WriteBuffer[\u001b[38;5;28mbytes\u001b[39m] \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mBytesIO() \u001b[38;5;28;01mif\u001b[39;00m path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m path\n\u001b[1;32m    480\u001b[0m impl\u001b[38;5;241m.\u001b[39mwrite(\n\u001b[1;32m    481\u001b[0m     df,\n\u001b[1;32m    482\u001b[0m     path_or_buf,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    488\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    489\u001b[0m )\n",
      "File \u001b[0;32m~/git/decp-airflow/.venv/lib/python3.10/site-packages/pandas/io/parquet.py:67\u001b[0m, in \u001b[0;36mget_engine\u001b[0;34m(engine)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m     65\u001b[0m             error_msgs \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m - \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(err)\n\u001b[0;32m---> 67\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m     68\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to find a usable engine; \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     69\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtried using: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpyarrow\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfastparquet\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     70\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA suitable version of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     71\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyarrow or fastparquet is required for parquet \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     72\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msupport.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     73\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrying to import the above resulted in these errors:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     74\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00merror_msgs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     75\u001b[0m     )\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m engine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyarrow\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m PyArrowImpl()\n",
      "\u001b[0;31mImportError\u001b[0m: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.\nA suitable version of pyarrow or fastparquet is required for parquet support.\nTrying to import the above resulted in these errors:\n - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.\n - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet."
     ]
    }
   ],
   "source": [
    "# *** ENREGISTREMENT AU FORMAT CSV ET PARQUET ***#\n",
    "\n",
    "import shutil\n",
    "\n",
    "distdir = Path(\"./dist\")\n",
    "if os.path.exists(distdir):\n",
    "    shutil.rmtree(\"dist\")\n",
    "os.mkdir(\"dist\")\n",
    "os.chdir(distdir)\n",
    "\n",
    "# CSV\n",
    "\n",
    "# Schéma cible\n",
    "df_standard = pd.read_csv(\n",
    "    \"https://raw.githubusercontent.com/ColinMaudry/decp-table-schema/main/exemples/exemple-valide.csv\",\n",
    "    index_col=None,\n",
    ")\n",
    "\n",
    "cible_colonnes = df_standard.columns\n",
    "df = df[cible_colonnes]\n",
    "# df_sans_titulaires = df.drop(columns=['titulaire.id', 'titulaire.denominationSociale', 'titulaire.typeIdentifiant'])\n",
    "\n",
    "df.to_csv(\"decp.csv\", index=None)\n",
    "df_sans_titulaires = df.drop(\n",
    "    columns=[\n",
    "        \"titulaire.id\",\n",
    "        \"titulaire.denominationSociale\",\n",
    "        \"titulaire.typeIdentifiant\",\n",
    "    ]\n",
    ")\n",
    "df_sans_titulaires = df.drop_duplicates()\n",
    "df_sans_titulaires.to_csv(\"decp-sans-titulaires.csv\", index=None)\n",
    "\n",
    "\n",
    "df.to_parquet(\"decp.parquet\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VALIDATION #\n",
    "\n",
    "from tableschema import Table, CastError\n",
    "\n",
    "table = Table(\n",
    "    \"decp.csv\",\n",
    "    schema=\"https://raw.githubusercontent.com/ColinMaudry/decp-table-schema/main/schema.json\",\n",
    ")\n",
    "try:\n",
    "    table.read(limit=50)\n",
    "except CastError as exception:\n",
    "    print(exception.errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA PACKAGE #\n",
    "\n",
    "from frictionless import Package, Resource, Pipeline, steps\n",
    "\n",
    "decp_resource: Resource = Resource(path=\"decp.csv\")\n",
    "\n",
    "# Cette méthode détecte les caractéristiques du CSV et tente de deviner les datatypes\n",
    "decp_resource.infer()\n",
    "\n",
    "decp_resource = decp_resource.transform(\n",
    "    Pipeline(\n",
    "        steps=[\n",
    "            steps.field_update(name=\"acheteur.id\", descriptor={\"type\": \"string\"}),\n",
    "            steps.field_update(name=\"acheteur.nom\", descriptor={\"type\": \"string\"}),\n",
    "            steps.field_update(name=\"titulaire.id\", descriptor={\"type\": \"string\"}),\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "\n",
    "decp_sans_titulaire_resource = Resource(path=\"decp-sans-titulaires.csv\")\n",
    "decp_sans_titulaire_resource.infer()\n",
    "\n",
    "\n",
    "decp_sans_titulaire_resource = decp_sans_titulaire_resource.transform(\n",
    "    Pipeline(\n",
    "        steps=[\n",
    "            steps.field_update(name=\"acheteur.id\", descriptor={\"type\": \"string\"}),\n",
    "            steps.field_update(name=\"acheteur.nom\", descriptor={\"type\": \"string\"}),\n",
    "            steps.field_remove(name=\"titulaire.id\"),\n",
    "            steps.field_remove(name=\"titulaire.denominationSociale\"),\n",
    "            steps.field_remove(name=\"titulaire.typeIdentifiant\"),\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "\n",
    "package = Package(\n",
    "    name=\"decp\",\n",
    "    title=\"DECP CSV\",\n",
    "    description=\"Données essentielles de la commande publique (FR) au format CSV.\",\n",
    "    resources=[decp_resource],\n",
    "    # it's possible to provide all the official properties like homepage, version, etc\n",
    ")\n",
    "\n",
    "package.to_json(\"datapackage.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "FrictionlessException",
     "evalue": "[package-error] The data package has an error: cannot retrieve metadata \"datapackage.json\" because \"[Errno 2] No such file or directory: 'datapackage.json'\" ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/git/decp-airflow/.venv/lib/python3.10/site-packages/frictionless/metadata/metadata.py:326\u001b[0m, in \u001b[0;36mMetadata.metadata_retrieve\u001b[0;34m(cls, descriptor, size)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 326\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdescriptor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m    327\u001b[0m         content \u001b[38;5;241m=\u001b[39m file\u001b[38;5;241m.\u001b[39mread(size)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'datapackage.json'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mFrictionlessException\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdecp.sqlite\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m      6\u001b[0m     os\u001b[38;5;241m.\u001b[39mremove(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdecp.sqlite\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 8\u001b[0m \u001b[43mdatapackage_to_datasette\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdbname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdecp.sqlite\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_package\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdatapackage.json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata_filename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdatasette_metadata.json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwrite_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreplace\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m os\u001b[38;5;241m.\u001b[39mchdir(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/home/git/decp-airflow\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/git/decp-airflow/.venv/lib/python3.10/site-packages/datapackage_to_datasette/utils.py:82\u001b[0m, in \u001b[0;36mdatapackage_to_datasette\u001b[0;34m(dbname, data_package, metadata_filename, write_mode)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m path\u001b[38;5;241m.\u001b[39mexists(metadata_filename) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m write_mode:\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m DataImportError(\n\u001b[1;32m     78\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetadata_filename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m already exists. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     79\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUse write_mode to replace or merge the existing file.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     80\u001b[0m     )\n\u001b[0;32m---> 82\u001b[0m dp \u001b[38;5;241m=\u001b[39m \u001b[43mPackage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_package\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     83\u001b[0m dp\u001b[38;5;241m.\u001b[39mpublish(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msqlite:///\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdbname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     85\u001b[0m metadata \u001b[38;5;241m=\u001b[39m get_metadata_object(dbname, dp)\n",
      "File \u001b[0;32m~/git/decp-airflow/.venv/lib/python3.10/site-packages/frictionless/package/factory.py:38\u001b[0m, in \u001b[0;36mFactory.__call__\u001b[0;34m(cls, source, control, basepath, packagify, *params, **options)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# Descriptor\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m source \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[1;32m     37\u001b[0m         platform\u001b[38;5;241m.\u001b[39mfrictionless\u001b[38;5;241m.\u001b[39mPackage,\n\u001b[0;32m---> 38\u001b[0m         \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_descriptor\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbasepath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbasepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m,  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m     39\u001b[0m     )\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Default\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[1;32m     43\u001b[0m     platform\u001b[38;5;241m.\u001b[39mfrictionless\u001b[38;5;241m.\u001b[39mPackage,\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mcls\u001b[39m, basepath\u001b[38;5;241m=\u001b[39mbasepath, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions),\n\u001b[1;32m     45\u001b[0m )\n",
      "File \u001b[0;32m~/git/decp-airflow/.venv/lib/python3.10/site-packages/frictionless/metadata/metadata.py:172\u001b[0m, in \u001b[0;36mMetadata.from_descriptor\u001b[0;34m(cls, descriptor, allow_invalid, **options)\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbasepath\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m)\u001b[38;5;241m.\u001b[39mparameters:\n\u001b[1;32m    171\u001b[0m         options[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbasepath\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m helpers\u001b[38;5;241m.\u001b[39mparse_basepath(descriptor)\n\u001b[0;32m--> 172\u001b[0m descriptor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetadata_retrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdescriptor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;66;03m# TODO: remove in next version\u001b[39;00m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;66;03m# Transform with a base class in case the type is not available\u001b[39;00m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata_transform(descriptor)\n",
      "File \u001b[0;32m~/git/decp-airflow/.venv/lib/python3.10/site-packages/frictionless/metadata/metadata.py:338\u001b[0m, in \u001b[0;36mMetadata.metadata_retrieve\u001b[0;34m(cls, descriptor, size)\u001b[0m\n\u001b[1;32m    336\u001b[0m Error \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata_Error \u001b[38;5;129;01mor\u001b[39;00m platform\u001b[38;5;241m.\u001b[39mfrictionless_errors\u001b[38;5;241m.\u001b[39mMetadataError\n\u001b[1;32m    337\u001b[0m note \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcannot retrieve metadata \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdescriptor\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m because \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexception\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 338\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m FrictionlessException(Error(note\u001b[38;5;241m=\u001b[39mnote)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexception\u001b[39;00m\n",
      "\u001b[0;31mFrictionlessException\u001b[0m: [package-error] The data package has an error: cannot retrieve metadata \"datapackage.json\" because \"[Errno 2] No such file or directory: 'datapackage.json'\" "
     ]
    }
   ],
   "source": [
    "# *** SQLITE ***#\n",
    "\n",
    "from datapackage_to_datasette import datapackage_to_datasette\n",
    "\n",
    "if os.path.exists(\"decp.sqlite\"):\n",
    "    os.remove(\"decp.sqlite\")\n",
    "\n",
    "datapackage_to_datasette(\n",
    "    dbname=\"decp.sqlite\",\n",
    "    data_package=\"datapackage.json\",\n",
    "    metadata_filename=\"datasette_metadata.json\",\n",
    "    write_mode=\"replace\",\n",
    ")\n",
    "\n",
    "os.chdir(\"/home/git/decp-airflow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *** PUBLICATION SUR DATA.GOUV.FR ***#\n",
    "\n",
    "import requests\n",
    "import json\n",
    "\n",
    "api_key = os.getenv(\"DATAGOUVFR_API_KEY\")\n",
    "\n",
    "api = \"https://www.data.gouv.fr/api/1\"\n",
    "dataset_id = \"608c055b35eb4e6ee20eb325\"\n",
    "resource_id_decp = \"8587fe77-fb31-4155-8753-f6a3c5e0f5c9\"\n",
    "# resource_id_sans_titulaires=\"834c14dd-037c-4825-958d-0a841c4777ae\"\n",
    "resource_id_datapackage = \"65194f6f-e273-4067-8075-56f072d56baf\"\n",
    "resource_id_sqlite = \"c6b08d03-7aa4-4132-b5b2-fd76633feecc\"\n",
    "\n",
    "\n",
    "def update_resource(api, dataset_id, resource_id, file_path, api_key):\n",
    "    url = f\"{api}/datasets/{dataset_id}/resources/{resource_id}/upload/\"\n",
    "    headers = {\"X-API-KEY\": api_key}\n",
    "    files = {\"file\": open(file_path, \"rb\")}\n",
    "    response = requests.post(url, files=files, headers=headers)\n",
    "    return response.json()\n",
    "\n",
    "\n",
    "print(\"Mise à jour de decp.csv...\")\n",
    "print(\n",
    "    json.dumps(\n",
    "        update_resource(api, dataset_id, resource_id_decp, \"decp.csv\", api_key),\n",
    "        indent=4,\n",
    "    )\n",
    ")\n",
    "\n",
    "# print(\"\\nMise à jour de decp-sans-titulaires.csv...\")\n",
    "# print(json.dumps(update_resource(api, dataset_id, resource_id_sans_titulaires, \"decp-sans-titulaires.csv\", api_key), indent=4))\n",
    "\n",
    "print(\"\\nMise à jour de datapackage.json...\")\n",
    "print(\n",
    "    json.dumps(\n",
    "        update_resource(\n",
    "            api, dataset_id, resource_id_datapackage, \"datapackage.json\", api_key\n",
    "        ),\n",
    "        indent=4,\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\"\\nMise à jour de decp.sqlite...\")\n",
    "print(\n",
    "    json.dumps(\n",
    "        update_resource(api, dataset_id, resource_id_sqlite, \"decp.sqlite\", api_key),\n",
    "        indent=4,\n",
    "    )\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "decp-airflow-UlwaW0Oi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
