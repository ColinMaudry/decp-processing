import os
import shutil

import polars as pl
from prefect import flow, task
from prefect.transactions import transaction

from config import (
    BASE_DF_COLUMNS,
    DATE_NOW,
    DECP_PROCESSING_PUBLISH,
    DIST_DIR,
    SIRENE_DATA_DIR,
)
from tasks.analyse import generate_stats
from tasks.clean import clean_decp
from tasks.enrich import add_unite_legale_data
from tasks.get import get_decp_json
from tasks.output import (
    save_to_files,
    save_to_sqlite,
)
from tasks.publish import publish_to_datagouv
from tasks.setup import create_sirene_data_dir
from tasks.transform import (
    concat_decp_json,
    extract_unique_acheteurs_siret,
    extract_unique_titulaires_siret,
    get_prepare_unites_legales,
    make_decp_sans_titulaires,
    normalize_tables,
    sort_columns,
)


@task(log_prints=True)
def get_clean_concat():
    print("R√©cup√©ration des donn√©es source...")
    files = get_decp_json()

    print("Nettoyage des donn√©es source et typage des colonnes...")
    files = clean_decp(files)

    print("Fusion des dataframes...")
    df = concat_decp_json(files)

    print("Ajout des donn√©es SIRENE...")
    lf: pl.LazyFrame = enrich_from_sirene(df.lazy())

    print("G√©n√©ration de l'artefact (statistiques) sur le base df...")
    df: pl.DataFrame = lf.collect(engine="streaming")
    generate_stats(df)

    if os.path.exists(DIST_DIR):
        shutil.rmtree(DIST_DIR)
    os.makedirs(DIST_DIR)

    print("Enregistrement des DECP aux formats CSV, Parquet...")
    df: pl.DataFrame = sort_columns(df, BASE_DF_COLUMNS)
    save_to_files(df, DIST_DIR / "decp")


@flow(log_prints=True)
def make_datalab_data():
    """T√¢ches consacr√©es √† la transformation des donn√©es dans un format
    adapt√© aux activit√©s du Datalab d'Anticor."""

    print("üöÄ  Cr√©ation des donn√©es pour le Datalab d'Anticor...")

    df: pl.DataFrame = pl.read_parquet(DIST_DIR / "decp.parquet")

    print("Enregistrement des DECP aux formats SQLite...")
    save_to_sqlite(
        df,
        "datalab",
        "data.gouv.fr.2022.clean",
        "uid, titulaire_id, titulaire_typeIdentifiant, modification_id",
    )

    print("Normalisation des tables...")
    normalize_tables(df)

    if DECP_PROCESSING_PUBLISH.lower() == "true":
        print("Publication sur data.gouv.fr...")
        publish_to_datagouv(context="datalab")
    else:
        print("Publication sur data.gouv.fr d√©sactiv√©e.")

    print("‚òëÔ∏è  Fin du flow make_datalab_data.")


@flow(log_prints=True)
def make_decpinfo_data():
    """T√¢ches consacr√©es √† la transformation des donn√©es dans un format
    # adapt√© √† decp.info"""

    print("üöÄ  Cr√©ation des donn√©es pour decp.info...")

    df: pl.DataFrame = pl.read_parquet(DIST_DIR / "decp.parquet")

    # DECP sans titulaires
    save_to_files(make_decp_sans_titulaires(df), DIST_DIR / "decp-sans-titulaires")

    # print("Ajout des colonnes manquantes...")
    # df = setup_tableschema_columns(df)

    # CREATION D'UN DATA PACKAGE (FRICTIONLESS DATA)

    # Pas la priorit√© pour le moment, prend du temps
    # print("Validation des donn√©es DECP avec le TableSchema...")
    # validate_decp_against_tableschema()

    # print("Cr√©ation du data package (JSON)....")
    # make_data_package()

    # PUBLICATION DES FICHIERS SUR DATA.GOUV.FR
    if DECP_PROCESSING_PUBLISH.lower() == "true":
        print("Publication sur data.gouv.fr...")
        publish_to_datagouv(context="decp")
    else:
        print("Publication sur data.gouv.fr d√©sactiv√©e.")

    print("‚òëÔ∏è  Fin du flow make_decpinfo_data.")

    return df


@flow(log_prints=True)
def decp_processing():
    print("üöÄ  D√©but du flow principal")

    # Donn√©es nettoy√©es et fusionn√©es
    get_clean_concat()

    # Fichiers d√©di√©s √† l'Open Data et decp.info
    make_decpinfo_data()

    # Base de donn√©es SQLite d√©di√©e aux activit√©s du Datalab d'Anticor
    make_datalab_data()

    print("‚òëÔ∏è  Fin du flow principal decp_processing.")


@task(log_prints=True)
def enrich_from_sirene(df: pl.LazyFrame):
    # Pr√©processing des donn√©es SIRENE si :
    # - le dossier n'existe pas encore (= les donn√©es n'ont pas d√©j√† √©t√© preprocessed ce mois-ci)
    # - on est au moins le 5 du mois (pour √™tre s√ªr que les donn√©es SIRENE ont √©t√© mises √† jour sur data.gouv.fr)
    if not SIRENE_DATA_DIR.exists() and int(DATE_NOW[-2:]) >= 5:
        sirene_preprocess()

    # DONN√âES SIRENE ACHETEURS

    print("Extraction des SIRET des acheteurs...")
    df_sirets_acheteurs = extract_unique_acheteurs_siret(df.clone())

    # print("Ajout des donn√©es √©tablissements (acheteurs)...")
    # df_sirets_acheteurs = add_etablissement_data(
    #     df_sirets_acheteurs, ["enseigne1Etablissement"], "acheteur_id"
    # )

    print("Ajout des donn√©es unit√©s l√©gales (acheteurs)...")
    df = add_unite_legale_data(
        df, df_sirets_acheteurs, siret_column="acheteur_id", type_siret="acheteur"
    )

    # print("Construction du champ acheteur_nom √† partir des donn√©es SIRENE...")
    # df_sirets_acheteurs = make_acheteur_nom(df_sirets_acheteurs)

    # print("Enregistrement des DECP aux formats CSV et Parquet...")
    # save_to_files(df, f"{DIST_DIR}/decp")

    # print("Suppression de colonnes et d√©duplication pour les DECP Sans Titulaires...")
    # df_decp_sans_titulaires = make_decp_sans_titulaires(df)
    # save_to_files(df_decp_sans_titulaires, f"{DIST_DIR}/decp-sans-titulaires")
    # del df_decp_sans_titulaires

    # DONN√âES SIRENE TITULAIRES

    # Enrichissement des donn√©es pas prioritaire
    # cf https://github.com/ColinMaudry/decp-processing/issues/17

    print("Extraction des SIRET des titulaires...")
    df_sirets_titulaires = extract_unique_titulaires_siret(df)

    # print("Ajout des donn√©es √©tablissements (titulaires)...")
    # df_sirets_titulaires = add_etablissement_data_to_titulaires(df_sirets_titulaires)

    print("Ajout des donn√©es unit√©s l√©gales (titulaires)...")
    df = add_unite_legale_data(
        df, df_sirets_titulaires, siret_column="titulaire_id", type_siret="titulaire"
    )
    # print("Am√©lioration des donn√©es unit√©s l√©gales des titulaires...")
    # df_sirets_titulaires = improve_titulaire_unite_legale_data(df_sirets_titulaires)

    # print("Renommage de certaines colonnes unit√©s l√©gales (titulaires)...")
    # df_sirets_titulaires = rename_titulaire_sirene_columns(df_sirets_titulaires)

    # print("Jointure pour cr√©er les donn√©es DECP Titulaires...")
    # df_decp_titulaires = merge_sirets_titulaires(df, df_sirets_titulaires)
    # del df_sirets_titulaires

    # print("Enregistrement des DECP Titulaires aux formats CSV et Parquet...")
    # save_to_files(df_decp_titulaires, f"{DIST_DIR}/decp-titulaires")
    # del df_decp_titulaires

    return df


@flow(log_prints=True)
def sirene_preprocess():
    """Pr√©traitement mensuel des donn√©es SIRENE afin d'√©conomiser du temps lors du traitement quotidien des DECP.
    Pour chaque ressource (unit√©s l√©gales, √©tablissements), un fichier parquet est produit.
    """

    print("üöÄ  Pr√©-traitement des donn√©es SIRENE")
    # Soit les t√¢ches de ce flow vont au bout (success), soit le dossier SIRENE_DATA_DIR est supprim√© (voir remove_sirene_data_dir())
    with transaction():
        create_sirene_data_dir()

        # TODO pr√©parer lest donn√©es √©tablissements

        # pr√©parer les donn√©es unit√©s l√©gales
        processed_parquet_path = SIRENE_DATA_DIR / "unites_legales.parquet"
        if not processed_parquet_path.exists():
            print("Pr√©pararion des unit√©s l√©gales...")
            get_prepare_unites_legales(processed_parquet_path)

    print("‚òëÔ∏è  Fin du flow sirene_preprocess.")


if __name__ == "__main__":
    decp_processing()
